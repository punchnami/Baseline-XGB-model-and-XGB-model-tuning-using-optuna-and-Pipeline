{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some packages might require the installation first \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as XGBClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading tabular data .csv\n",
    "train_data = pd.read_csv('PATH_TO_TRAIN_DATASET')\n",
    "test_data = pd.read_csv('PATH_TO_TEST_DATASET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.copy()\n",
    "y_train = train_data['YOUR_TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline XGBmodel without tuning\n",
    "model = XGBClassifier(\n",
    "                      learning_rate =0.2,\n",
    "                      n_estimators=1000,\n",
    "                      max_depth=10,\n",
    "                      min_child_weight=4,\n",
    "                      gamma=0,\n",
    "                      subsample=0.8,\n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic',\n",
    "                      nthread=4,\n",
    "                      scale_pos_weight=1,\n",
    "                      seed=27,\n",
    "                      eval_metric='auc')\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data\n",
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning XGB model using Optuna\n",
    "    \n",
    "def objective(trial,X,y):\n",
    " # 'is_unbalance':True,\n",
    "    params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'booster': 'gbtree',\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 11),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'alpha': trial.suggest_float('alpha', 0, 10),\n",
    "            'lambda': trial.suggest_float('lambda', 0, 10),\n",
    "            'scale_pos_weight': trial.suggest_int('scale_pos_weight', 0, 10),\n",
    "            'n_estimators': 1000\n",
    "            }\n",
    "    \n",
    "    xgb_model = XGBClassifier(**params)\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[('classifier', xgb_model)])\n",
    "    \n",
    "    # Fit the model\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    cv_scores = cross_val_score(xgb_model, X, y, cv=10, n_jobs=-1, scoring=\"roc_auc\")\n",
    "    score = np.mean(cv_scores)\n",
    "    # scorestd = cv_scores.std()\n",
    "    return score  # Replace with appropriate metric\n",
    "\n",
    "# Create a study object and specify the direction is 'maximize'.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start the optimization\n",
    "study.optimize(lambda trial: objective(trial, x_train, y_train), n_trials=100,  gc_after_trial=True)\n",
    "\n",
    "# Print the optimal parameters\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training using the best params result from the hyperparameter tuning above\n",
    "\n",
    "params = {'INPUT_THE_BEST_PARAMS'}\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data after tuning\n",
    "\n",
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prediction results to tabular data('.csv') file\n",
    "\n",
    "pred.to_csv('PATH_TO_SAVE_THE_PREDICTION')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
